{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import csv\n",
    "import sys\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "\n",
    "def token2features(sentence, i):\n",
    "\n",
    "    token = sentence[i][0]\n",
    "    postag = sentence[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'token': token.lower(),\n",
    "        'postag': postag\n",
    "    }\n",
    "    if i == 0:\n",
    "        features['BOS'] = True\n",
    "    elif i == len(sentence) -1:\n",
    "        features['EOS'] = True\n",
    "    \n",
    "    \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [token2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    #if you added features to your input file, make sure to add them here as well.\n",
    "    #print([ner for token, postag, chunklabel, label, pretoken, nexttoken, prepos,nextpos, capital, ner in sent])\n",
    "    return [label for token, postag, chunklabel, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, chunklabel, label  in sent]\n",
    "    \n",
    "    \n",
    "def extract_sents_from_conll(inputfile):\n",
    "    sents = []\n",
    "    current_sent = []\n",
    "\n",
    "    with open(inputfile, 'r') as my_conll:\n",
    "        for line in my_conll:\n",
    "            row = line.strip(\"\\n\").split('\\t')\n",
    "            \n",
    "            if len(row) == 1:\n",
    "                 sents.append(current_sent)\n",
    "                 current_sent = []\n",
    "            else:\n",
    "                current_sent.append(tuple(row))\n",
    "    \n",
    "    return sents\n",
    "\n",
    "\n",
    "def train_crf_model(X_train, y_train):\n",
    "\n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "        algorithm='lbfgs',\n",
    "        c1=0.1,\n",
    "        c2=0.1,\n",
    "        max_iterations=100,\n",
    "        all_possible_transitions=True\n",
    "    )\n",
    "    crf.fit(X_train, y_train)\n",
    "    \n",
    "    return crf\n",
    "\n",
    "def create_crf_model(trainingfile):\n",
    "\n",
    "    train_sents = extract_sents_from_conll(trainingfile)\n",
    "    X_train = [sent2features(s) for s in train_sents]\n",
    "    y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "    crf = train_crf_model(X_train, y_train)\n",
    "    \n",
    "    return crf\n",
    "\n",
    "\n",
    "def run_crf_model(crf, evaluationfile):\n",
    "\n",
    "    test_sents = extract_sents_from_conll(evaluationfile)\n",
    "    X_test = [sent2features(s) for s in test_sents]\n",
    "    y_pred = crf.predict(X_test)\n",
    "    \n",
    "    return y_pred, X_test\n",
    "\n",
    "def write_out_evaluation(eval_data, pred_labels, outputfile):\n",
    "\n",
    "    outfile = open(outputfile, 'w')\n",
    "    \n",
    "    for evalsents, predsents in zip(eval_data, pred_labels):\n",
    "        for data, pred in zip(evalsents, predsents):\n",
    "            outfile.write(data.get('token') + \"\\t\" + pred + \"\\n\")\n",
    "\n",
    "def train_and_run_crf_model(trainingfile, evaluationfile, outputfile):\n",
    "\n",
    "    crf = create_crf_model(trainingfile)\n",
    "    pred_labels, eval_data = run_crf_model(crf, evaluationfile)\n",
    "    write_out_evaluation(eval_data, pred_labels, outputfile)\n",
    "\n",
    "def main(argv):\n",
    "    \n",
    "    #argv = sys.argv\n",
    "    \n",
    "    \n",
    "    trainingfile = argv[1]\n",
    "    evaluationfile = argv[2]\n",
    "    outputfile = argv[3]\n",
    "    \n",
    "    train_and_run_crf_model(trainingfile, evaluationfile, outputfile)\n",
    "\n",
    "    \n",
    "gold = 'data/conll2003.dev.conll'\n",
    "gold_train = 'data/conll2003.train.conll'\n",
    "argv = ['mypython_program',gold_train, gold, 'data/conll2003.dev.conll.crfconll']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdata = 'data/conll2003.dev.crfconll'\n",
    "outputfile = 'data/conll2003.dev.crfconll_revised'\n",
    "\n",
    "inputdata1 = 'data/conll2003.dev.conll'\n",
    "outputfile1 = 'data/conll2003.dev.conll_revised'\n",
    "\n",
    "def narrow_file(inputdata,outputfile, mode ='crf'):\n",
    "    \"\"\"\n",
    "    :para inputdata: the path to predicted output (conll2003 dev.crfonll) file \n",
    "     and original test file (conll2003.dev)\n",
    "    :para outputfile: the path to the outputfile \n",
    "    \n",
    "    This function will return an outputfile with added header, so that we can use \n",
    "    pandas to read the file easily. \n",
    "    \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    with open (outputfile, 'w', newline='', encoding = 'utf-8') as outfile:\n",
    "        with open(inputdata, 'r', encoding='utf8') as infile:\n",
    "            for line in infile:\n",
    "                if count ==0:\n",
    "                    if mode == 'crf':\n",
    "                        outfile.write('token'+'\\t'+'predict' +'\\n') \n",
    "                        outfile.write(line.rstrip('\\n') +'\\n')  \n",
    "                    else:\n",
    "                        outfile.write('token'+'\\t'+'pos'+'\\t'+'chunklabel'+'\\t'+'gold' +'\\n') \n",
    "                        outfile.write(line.rstrip('\\n') +'\\n')  \n",
    "                else:\n",
    "                    if len(line.rstrip('\\n').split())>0:\n",
    "                        outfile.write(line.rstrip('\\n') +'\\n') \n",
    "                    else:\n",
    "                        pass\n",
    "                count +=1\n",
    "                \n",
    "\n",
    "narrow_file(inputdata ,outputfile, mode='crf')    \n",
    "narrow_file(inputdata1 ,outputfile1, mode='dev')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
